{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "233fa36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Función: download_csv_from_public_s3\n",
    "# ---------------------------------------------------------\n",
    "def download_csv_from_public_s3(bucket_name: str, file_key: str, sep: str = None) -> pd.DataFrame:\n",
    "    url = f\"https://{bucket_name}.s3.amazonaws.com/{file_key}\"\n",
    "    return pd.read_csv(\n",
    "        url,\n",
    "        sep=sep,\n",
    "        engine=\"python\",\n",
    "        quotechar='\"',\n",
    "        escapechar=\"\\\\\",\n",
    "        on_bad_lines=\"skip\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "296394a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datasets desde el bucket público a memoria\n",
    "df_netflix = download_csv_from_public_s3(\"desafio-rkd\", \"netflix_titles.csv\", sep=\";\")\n",
    "df_disney = download_csv_from_public_s3(\"desafio-rkd\", \"disney_plus_titles.csv\", sep=\",\")\n",
    "\n",
    "# Agregar columna de plataforma\n",
    "df_netflix[\"platform\"] = \"Netflix\"\n",
    "df_disney[\"platform\"] = \"Disney+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69484be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 1. Configuración inicial\n",
    "# ============================================\n",
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Cargar variables de entorno\n",
    "load_dotenv()\n",
    "user = os.getenv(\"DB_USER\")\n",
    "password = os.getenv(\"DB_PASSWORD\")\n",
    "host = os.getenv(\"DB_HOST\")\n",
    "port = os.getenv(\"DB_PORT\", \"5432\")\n",
    "db = os.getenv(\"DB_NAME\")\n",
    "\n",
    "engine = create_engine(f\"postgresql://{user}:{password}@{host}:{port}/{db}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b2ac4ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "450"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# ============================================\n",
    "# 2. Carga de datos crudos en capa RAW\n",
    "# ============================================\n",
    "\n",
    "# Fecha/hora actual\n",
    "now = datetime.now()\n",
    "\n",
    "# Agregar columnas de auditoría a Netflix\n",
    "df_netflix_raw = df_netflix.copy()\n",
    "df_netflix_raw[\"audit_created\"] = now\n",
    "df_netflix_raw[\"audit_updated\"] = now\n",
    "\n",
    "# Agregar columnas de auditoría a Disney\n",
    "df_disney_raw = df_disney.copy()\n",
    "df_disney_raw[\"audit_created\"] = now\n",
    "df_disney_raw[\"audit_updated\"] = now\n",
    "\n",
    "# Insertar en schema RAW\n",
    "df_netflix_raw.to_sql(\"raw_netflix\", engine, schema=\"raw\", if_exists=\"replace\", index=False)\n",
    "df_disney_raw.to_sql(\"raw_disney\", engine, schema=\"raw\", if_exists=\"replace\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e37e688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# ============================================\n",
    "# 3. Limpieza y normalización\n",
    "# ============================================\n",
    "\n",
    "# Normalizar duración a minutos\n",
    "df_netflix[\"duration_minutes\"] = df_netflix[\"duration\"].str.extract(r'(\\d+)').astype(float)\n",
    "df_disney[\"duration_minutes\"] = df_disney[\"duration\"].str.extract(r'(\\d+)').astype(float)\n",
    "\n",
    "# Convertir fechas\n",
    "df_netflix[\"date_added\"] = pd.to_datetime(df_netflix[\"date_added\"], errors=\"coerce\")\n",
    "df_disney[\"date_added\"] = pd.to_datetime(df_disney[\"date_added\"], errors=\"coerce\")\n",
    "\n",
    "# Normalizar texto en cast\n",
    "df_netflix[\"cast\"] = df_netflix[\"cast\"].fillna(\"\").str.strip()\n",
    "df_disney[\"cast\"] = df_disney[\"cast\"].fillna(\"\").str.strip()\n",
    "\n",
    "# Eliminar duplicados\n",
    "df_netflix = df_netflix.drop_duplicates()\n",
    "df_disney = df_disney.drop_duplicates()\n",
    "\n",
    "# Unificar en un solo DataFrame procesado\n",
    "df_processed = pd.concat([df_netflix, df_disney])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3023a441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 4. Carga en capa PROCESSED\n",
    "# ============================================\n",
    "\n",
    "# ---- 4.1 Plataformas ----\n",
    "df_platforms = pd.DataFrame({\"name\": df_processed[\"platform\"].dropna().unique()})\n",
    "df_platforms = df_platforms.drop_duplicates(subset=[\"name\"])\n",
    "\n",
    "# Plataformas ya existentes en la DB\n",
    "existing_platforms = pd.read_sql(\"SELECT name FROM processed.platforms\", engine)[\"name\"].tolist()\n",
    "\n",
    "# Filtrar solo las nuevas\n",
    "df_platforms = df_platforms[~df_platforms[\"name\"].isin(existing_platforms)]\n",
    "\n",
    "# Insertar solo si hay nuevas\n",
    "if not df_platforms.empty:\n",
    "    df_platforms.to_sql(\"platforms\", engine, schema=\"processed\", if_exists=\"append\", index=False)\n",
    "\n",
    "# Mapear IDs de plataformas\n",
    "platforms_map = pd.read_sql(\"SELECT * FROM processed.platforms\", engine).set_index(\"name\")[\"platform_id\"].to_dict()\n",
    "\n",
    "# ---- 4.2 Titles ----\n",
    "import datetime\n",
    "current_year = datetime.datetime.now().year\n",
    "\n",
    "# Limpiar release_year\n",
    "df_processed[\"release_year\"] = (\n",
    "    df_processed[\"release_year\"].astype(str).str.extract(r\"(\\d{4})\").astype(\"Int64\")\n",
    ")\n",
    "df_processed.loc[~df_processed[\"release_year\"].between(1900, current_year), \"release_year\"] = pd.NA\n",
    "\n",
    "# Limpiar duration_minutes\n",
    "df_processed[\"duration_minutes\"] = (\n",
    "    df_processed[\"duration_minutes\"].astype(str).str.extract(r\"(\\d+)\").astype(\"Int64\")\n",
    ")\n",
    "\n",
    "# Filtrar valores absurdos en duración (ej. <=10 minutos o >1000 minutos)\n",
    "df_processed.loc[\n",
    "    (df_processed[\"duration_minutes\"] <= 10) | (df_processed[\"duration_minutes\"] > 1000),\n",
    "    \"duration_minutes\"\n",
    "] = pd.NA\n",
    "\n",
    "# Construir DataFrame final\n",
    "df_titles = pd.DataFrame({\n",
    "    \"show_id\": df_processed[\"show_id\"],\n",
    "    \"title\": df_processed[\"title\"],\n",
    "    \"type\": df_processed[\"type\"],\n",
    "    \"release_year\": df_processed[\"release_year\"],\n",
    "    \"rating\": df_processed[\"rating\"],\n",
    "    \"duration_minutes\": df_processed[\"duration_minutes\"],\n",
    "    \"date_added\": df_processed[\"date_added\"],\n",
    "    \"description\": df_processed[\"description\"],\n",
    "    \"platform_id\": df_processed[\"platform\"].map(platforms_map)\n",
    "})\n",
    "df_titles = df_titles.drop_duplicates(subset=[\"show_id\"])\n",
    "\n",
    "# Reemplazar NaT por None en columnas de fecha\n",
    "df_titles[\"date_added\"] = df_titles[\"date_added\"].where(df_titles[\"date_added\"].notna(), None)\n",
    "\n",
    "# ---- UPSERT en titles ----\n",
    "from sqlalchemy import text\n",
    "import pandas as pd\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    for _, row in df_titles.iterrows():\n",
    "        row_dict = row.to_dict()\n",
    "\n",
    "        # Convertir NaT/NaN a None en columnas de fecha y numéricas\n",
    "        for col in [\"date_added\", \"release_year\", \"duration_minutes\"]:\n",
    "            if pd.isna(row_dict[col]):\n",
    "                row_dict[col] = None\n",
    "\n",
    "        conn.execute(text(\"\"\"\n",
    "            INSERT INTO processed.titles (\n",
    "                show_id, title, type, release_year, rating, duration_minutes,\n",
    "                date_added, description, platform_id\n",
    "            )\n",
    "            VALUES (\n",
    "                :show_id, :title, :type, :release_year, :rating, :duration_minutes,\n",
    "                :date_added, :description, :platform_id\n",
    "            )\n",
    "            ON CONFLICT (show_id) DO UPDATE SET\n",
    "                title = EXCLUDED.title,\n",
    "                type = EXCLUDED.type,\n",
    "                release_year = EXCLUDED.release_year,\n",
    "                rating = EXCLUDED.rating,\n",
    "                duration_minutes = EXCLUDED.duration_minutes,\n",
    "                date_added = EXCLUDED.date_added,\n",
    "                description = EXCLUDED.description,\n",
    "                platform_id = EXCLUDED.platform_id,\n",
    "                updated_at = CURRENT_TIMESTAMP;\n",
    "        \"\"\"), row_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a119a4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 5. Directores y relación títulos-directores\n",
    "# ============================================\n",
    "\n",
    "# ---- Directores únicos ----\n",
    "df_directors = pd.DataFrame({\"name\": df_processed[\"director\"].dropna().unique()})\n",
    "df_directors = df_directors.drop_duplicates(subset=[\"name\"])\n",
    "\n",
    "# Directores ya existentes en la DB\n",
    "existing_directors = pd.read_sql(\"SELECT name FROM processed.directors\", engine)[\"name\"].tolist()\n",
    "\n",
    "# Filtrar solo los nuevos\n",
    "df_directors = df_directors[~df_directors[\"name\"].isin(existing_directors)]\n",
    "\n",
    "# Insertar solo si hay nuevos\n",
    "if not df_directors.empty:\n",
    "    df_directors.to_sql(\"directors\", engine, schema=\"processed\", if_exists=\"append\", index=False)\n",
    "\n",
    "# Mapear IDs de directores\n",
    "directors_map = pd.read_sql(\"SELECT * FROM processed.directors\", engine).set_index(\"name\")[\"director_id\"].to_dict()\n",
    "\n",
    "# ---- Relación títulos-directores ----\n",
    "# Recuperar IDs de titles\n",
    "titles_db = pd.read_sql(\"SELECT show_id, title_id FROM processed.titles\", engine)\n",
    "\n",
    "# Construir DataFrame de relación\n",
    "df_title_directors = pd.DataFrame({\n",
    "    \"show_id\": df_processed[\"show_id\"],\n",
    "    \"director\": df_processed[\"director\"]\n",
    "}).dropna()\n",
    "\n",
    "# Mapear show_id -> title_id\n",
    "df_title_directors = df_title_directors.merge(titles_db, on=\"show_id\", how=\"inner\")\n",
    "\n",
    "# Mapear director -> director_id\n",
    "df_title_directors[\"director_id\"] = df_title_directors[\"director\"].map(directors_map)\n",
    "\n",
    "# Seleccionar solo columnas necesarias y eliminar duplicados\n",
    "df_title_directors = df_title_directors[[\"title_id\", \"director_id\"]].dropna().drop_duplicates()\n",
    "\n",
    "# ---- UPSERT en title_directors ----\n",
    "from sqlalchemy import text\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    for _, row in df_title_directors.iterrows():\n",
    "        conn.execute(text(\"\"\"\n",
    "            INSERT INTO processed.title_directors (title_id, director_id)\n",
    "            VALUES (:title_id, :director_id)\n",
    "            ON CONFLICT (title_id, director_id) DO NOTHING;\n",
    "        \"\"\"), row.to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee9db0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 6. Actores y relación títulos-actores\n",
    "# ============================================\n",
    "\n",
    "# ---- Actores únicos ----\n",
    "# Actores únicos\n",
    "all_actors = df_processed[\"cast\"].dropna().str.split(\", \")\n",
    "actors_list = [actor.strip() for sublist in all_actors for actor in sublist if actor.strip() != \"\"]\n",
    "actors_unique = pd.unique(pd.Series(actors_list))\n",
    "df_actors = pd.DataFrame({\"name\": actors_unique})\n",
    "\n",
    "\n",
    "# Actores ya existentes en la DB\n",
    "existing_actors = pd.read_sql(\"SELECT name FROM processed.actors\", engine)[\"name\"].tolist()\n",
    "\n",
    "# Filtrar solo los nuevos\n",
    "df_actors = df_actors[~df_actors[\"name\"].isin(existing_actors)]\n",
    "\n",
    "# Insertar solo si hay nuevos\n",
    "if not df_actors.empty:\n",
    "    df_actors.to_sql(\"actors\", engine, schema=\"processed\", if_exists=\"append\", index=False)\n",
    "\n",
    "# Mapear IDs de actores\n",
    "actors_map = pd.read_sql(\"SELECT * FROM processed.actors\", engine).set_index(\"name\")[\"actor_id\"].to_dict()\n",
    "\n",
    "# ---- Relación títulos-actores ----\n",
    "# Recuperar IDs de titles\n",
    "titles_db = pd.read_sql(\"SELECT show_id, title_id FROM processed.titles\", engine)\n",
    "\n",
    "rows = []\n",
    "for _, row in df_processed.iterrows():\n",
    "    if pd.notna(row[\"cast\"]) and row[\"cast\"].strip() != \"\":\n",
    "        for actor in row[\"cast\"].split(\", \"):\n",
    "            actor = actor.strip()\n",
    "            if actor in actors_map:\n",
    "                # Mapear show_id -> title_id\n",
    "                title_id = titles_db.loc[titles_db[\"show_id\"] == row[\"show_id\"], \"title_id\"].values\n",
    "                if len(title_id) > 0:\n",
    "                    rows.append({\"title_id\": title_id[0], \"actor_id\": actors_map[actor]})\n",
    "\n",
    "df_title_actors = pd.DataFrame(rows).drop_duplicates()\n",
    "\n",
    "# ---- UPSERT en title_actors ----\n",
    "from sqlalchemy import text\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    for _, row in df_title_actors.iterrows():\n",
    "        row_dict = row.to_dict()\n",
    "        conn.execute(text(\"\"\"\n",
    "            INSERT INTO processed.title_actors (title_id, actor_id)\n",
    "            VALUES (:title_id, :actor_id)\n",
    "            ON CONFLICT (title_id, actor_id) DO NOTHING;\n",
    "        \"\"\"), row_dict)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
